{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:33.056199Z",
     "start_time": "2021-03-18T05:50:29.079776Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV as logreg\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from transformers import pipeline\n",
    "\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.524284Z",
     "start_time": "2021-03-18T05:50:33.078643Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_pos = pd.read_csv('./data/poli_pos.csv')\n",
    "poli_neg = pd.read_csv('./data/poli_neg.csv')\n",
    "poli_val = pd.read_csv('./data/poli_val.csv')\n",
    "topics_neg = pd.read_csv('./data/topics_neg.csv')\n",
    "topics_pos = pd.read_csv('./data/topics_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.528188Z",
     "start_time": "2021-03-18T05:50:37.525261Z"
    }
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.535997Z",
     "start_time": "2021-03-18T05:50:37.529166Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.543806Z",
     "start_time": "2021-03-18T05:50:37.537950Z"
    }
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.554540Z",
     "start_time": "2021-03-18T05:50:37.544781Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_neg['target'] = 0 \n",
    "poli_pos['target'] = 1 \n",
    "topics_neg['target'] = 0\n",
    "topics_pos['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.563323Z",
     "start_time": "2021-03-18T05:50:37.556493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'datetime', 'tweet_id', 'text', 'user_name', 'target'], dtype='object')\n",
      "Index(['Unnamed: 0', 'datetime', 'tweet_id', 'text', 'user_name', 'target'], dtype='object')\n",
      "Index(['Unnamed: 0', 'datetime', 'tweet_id', 'text', 'user_name', 'target'], dtype='object')\n",
      "Index(['Unnamed: 0', 'datetime', 'tweet_id', 'text', 'keyword', 'target'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(poli_neg.columns)\n",
    "print(poli_pos.columns)\n",
    "print(topics_neg.columns)\n",
    "print(topics_pos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.721472Z",
     "start_time": "2021-03-18T05:50:37.564806Z"
    }
   },
   "outputs": [],
   "source": [
    "# note: I will have to exclude the keyword column until I have added appropriate\n",
    "# keywords throughout the data.  Right now there are too few, and they are too predictive.\n",
    "poli_neg.drop(columns=['Unnamed: 0', 'tweet_id', 'user_name', 'datetime'], inplace=True)\n",
    "poli_pos.drop(columns=['Unnamed: 0', 'tweet_id', 'user_name', 'datetime'], inplace=True)\n",
    "topics_neg.drop(columns=['Unnamed: 0', 'tweet_id', 'user_name', 'datetime'], inplace=True)\n",
    "topics_pos.drop(columns=['Unnamed: 0', 'tweet_id', 'datetime', 'keyword'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.760512Z",
     "start_time": "2021-03-18T05:50:37.723425Z"
    }
   },
   "outputs": [],
   "source": [
    "df_topics = pd.concat([topics_pos, topics_neg], ignore_index=True)\n",
    "df_poli = pd.concat([poli_pos, poli_neg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:37.809823Z",
     "start_time": "2021-03-18T05:50:37.761489Z"
    }
   },
   "outputs": [],
   "source": [
    "X_poli = df_poli.drop(columns=['target'])\n",
    "y_poli = df_poli['target']\n",
    "X_topics = df_topics.drop(columns=['target'])\n",
    "y_topics = df_topics['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:38.923326Z",
     "start_time": "2021-03-18T05:50:37.810800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train_poli, X_test_poli, y_train_poli, y_test_poli = train_test_split(X_poli,\n",
    "                                                                        y_poli,\n",
    "                                                                        test_size=0.2,\n",
    "                                                                        stratify=y_poli,\n",
    "                                                                        random_state=42)\n",
    "\n",
    "X_train_topics, X_test_topics, y_train_topics, y_test_topics = train_test_split(X_topics,\n",
    "                                                                                y_topics,\n",
    "                                                                                test_size=0.2,\n",
    "                                                                                stratify=y_topics,\n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:38.929183Z",
     "start_time": "2021-03-18T05:50:38.924302Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom stopwords to manually zero in on more predictive words\n",
    "\n",
    "custom = ['https', 'trump', 'realdonaldtrump', 'rt', 'health', 'country', \n",
    "          'just', 'help', 'thank', 'time', 'senate', 'http', 'american', \n",
    "          'americans', 'act', 'vote', 'pandemic', 'like', 'america', 'state', \n",
    "          'support', 'day', 'workers', 'right', 'years', 'working', 'good', \n",
    "          'thanks', 'families', 'covid', 'crisis', 'election', 'big', \n",
    "          'congress', 'let', 'want', 'national', 'going', 'know', 'relief',  \n",
    "          'house', 'public', 'year', 'federal', 'continue', 've', \n",
    "          'states', 'justice', 'way', 'ensure', 'jobs', 'law', 'businesses', \n",
    "          'proud', 'administration', 'small', 'world', 'stop', 'job', 'safe',\n",
    "          'best', 'important', 'biden', 'doing', 'economy', 'better', 'needs',\n",
    "          'week', 'join', 'funding', 'forward', 'economic']\n",
    "\n",
    "\n",
    "combined_words = text.ENGLISH_STOP_WORDS.union(custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:50:38.938945Z",
     "start_time": "2021-03-18T05:50:38.930159Z"
    }
   },
   "outputs": [],
   "source": [
    "# implement countvectorizer\n",
    "cvec = CountVectorizer(analyzer=\"word\",\n",
    "                       encoding='utf-8',\n",
    "                       decode_error='ignore',\n",
    "                       strip_accents='unicode',\n",
    "                       lowercase=True,\n",
    "                       max_df=0.95,\n",
    "                       min_df=0.01,\n",
    "                       stop_words=combined_words,\n",
    "                       max_features=5000,\n",
    "                       ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:57:19.041278Z",
     "start_time": "2021-03-18T05:57:18.846550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_topics.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:57:22.433026Z",
     "start_time": "2021-03-18T05:57:22.347134Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-294d3c14820a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_topics.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_test_topics.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:57:39.459763Z",
     "start_time": "2021-03-18T05:57:24.227365Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply cvec to train and test sets\n",
    "poli_X = pd.DataFrame(cvec.fit_transform(X_train_poli['text']).todense(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "poli_X_test = pd.DataFrame(cvec.fit_transform(X_test_poli['text']).todense(),\n",
    "                           columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:00:07.693933Z",
     "start_time": "2021-03-18T05:57:39.460740Z"
    }
   },
   "outputs": [],
   "source": [
    "topics_X = pd.DataFrame(cvec.fit_transform(X_train_topics['text']).todense(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "topics_X_test = pd.DataFrame(cvec.fit_transform(X_test_topics['text']).todense(),\n",
    "                           columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:00:08.255068Z",
     "start_time": "2021-03-18T06:00:07.695853Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-209a0db7d162>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_topics.dropna(subset=['text'], inplace=True)\n",
      "<ipython-input-32-209a0db7d162>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_topics.dropna(subset=['text'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_train_topics.dropna(subset=['text'], inplace=True)\n",
    "X_test_topics.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:00:08.258940Z",
     "start_time": "2021-03-18T06:00:08.256011Z"
    }
   },
   "outputs": [],
   "source": [
    "# # re-add the username and datetime columns to the temporary df, then replace the original with the vectorized version\n",
    "\n",
    "# X_train_poli = pd.concat([poli_X, X_train_poli['datetime']], axis=1)\n",
    "# X_test_poli = pd.concat([poli_X_test, X_test_poli['datetime']], axis=1)\n",
    "# X_train_topics = pd.concat([topics_X, X_train_topics['datetime']], axis=1)\n",
    "# X_test_topics = pd.concat([topics_X_test, X_test_topics['datetime']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:00:08.266748Z",
     "start_time": "2021-03-18T06:00:08.259916Z"
    }
   },
   "outputs": [],
   "source": [
    "l1 = logreg(cv=5,\n",
    "            penalty='l1',\n",
    "            scoring=None,\n",
    "            solver='liblinear',\n",
    "            tol=0.001,\n",
    "            max_iter=200,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-2,\n",
    "            verbose=1,\n",
    "            refit=True,\n",
    "            intercept_scaling=1.0,\n",
    "            multi_class='auto',\n",
    "            random_state=42,\n",
    "            l1_ratios=None,)\n",
    "\n",
    "l2 = logreg(cv=5,\n",
    "            penalty='l2',\n",
    "            scoring=None,\n",
    "            solver='lbfgs',\n",
    "            tol=0.001,\n",
    "            max_iter=200,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-2,\n",
    "            verbose=1,\n",
    "            refit=True,\n",
    "            intercept_scaling=1.0,\n",
    "            multi_class='auto',\n",
    "            random_state=42,\n",
    "            l1_ratios=None,)\n",
    "\n",
    "lr_net = logreg(cv=5,\n",
    "                penalty='elasticnet',\n",
    "                scoring=None,\n",
    "                solver='saga',\n",
    "                tol=0.001,\n",
    "                max_iter=200,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-2,\n",
    "                verbose=1,\n",
    "                refit=True,\n",
    "                intercept_scaling=1.0,\n",
    "                multi_class='auto',\n",
    "                random_state=42,\n",
    "                l1_ratios=.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:38.616472Z",
     "start_time": "2021-03-18T06:05:38.612540Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_sc = StandardScaler()\n",
    "\n",
    "poli_pipe1 = Pipeline([\n",
    "    ('scaler', poli_sc),\n",
    "    ('model', l1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishing null model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:39.046858Z",
     "start_time": "2021-03-18T06:05:39.039049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.50144\n",
       "0    0.49856\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_poli.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:39.237179Z",
     "start_time": "2021-03-18T06:05:39.231322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.501418\n",
       "0    0.498582\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_poli.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.886222Z",
     "start_time": "2021-03-18T06:05:39.437258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   5 | elapsed:   17.6s remaining:   26.5s\n",
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   18.8s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 122 features, but this StandardScaler is expecting 116 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-79482c0956da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpoli_train1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoli_pipe1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoli_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_poli\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpoli_test1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoli_pipe1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoli_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_poli\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'LogReg L1, score on training set: {poli_train1}, score on test set: {poli_test1}.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m         X = self._validate_data(X, reset=False,\n\u001b[0m\u001b[0;32m    792\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 )\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    378\u001b[0m                     \u001b[1;34m'X has {} features, but this {} is expecting {} features '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                     'as input.'.format(n_features, self.__class__.__name__,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 122 features, but this StandardScaler is expecting 116 features as input."
     ]
    }
   ],
   "source": [
    "poli_pipe1.fit(poli_X, y_train_poli)\n",
    "\n",
    "poli_train1 = poli_pipe1.score(poli_X, y_train_poli)\n",
    "poli_test1 = poli_pipe1.score(poli_X_test, y_test_poli)\n",
    "print(f'LogReg L1, score on training set: {poli_train1}, score on test set: {poli_test1}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.888174Z",
     "start_time": "2021-03-18T06:05:45.108Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.889152Z",
     "start_time": "2021-03-18T06:05:45.298Z"
    }
   },
   "outputs": [],
   "source": [
    "set(zip(poli_X.columns, l1.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.890126Z",
     "start_time": "2021-03-18T06:05:45.483Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_X.sum().sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.892078Z",
     "start_time": "2021-03-18T06:05:45.864Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot top occuring words\n",
    "poli_X.sum().sort_values(ascending=False).head(50).plot(kind='barh', figsize=(13,13));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.893055Z",
     "start_time": "2021-03-18T06:05:46.310Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_pipe2 = Pipeline([\n",
    "    ('scaler', poli_sc),\n",
    "    ('model', l2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.894031Z",
     "start_time": "2021-03-18T06:05:46.770Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_pipe2.fit(poli_X, y_train_poli)\n",
    "\n",
    "poli_train2 = poli_pipe2.score(poli_X, y_train_poli)\n",
    "poli_test2 = poli_pipe2.score(poli_X_test, y_test_poli)\n",
    "print(f'LogReg L2, score on training set: {poli_train2}, score on test set: {poli_test2}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.895006Z",
     "start_time": "2021-03-18T06:05:47.017Z"
    }
   },
   "outputs": [],
   "source": [
    "set(zip(poli_X.columns, l2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.896958Z",
     "start_time": "2021-03-18T06:05:47.471Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_pipe3 = Pipeline([\n",
    "    ('scaler', poli_sc),\n",
    "    ('model', lr_net)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.896958Z",
     "start_time": "2021-03-18T06:05:47.679Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_pipe3.fit(poli_X, y_train_poli)\n",
    "\n",
    "poli_train3 = poli_pipe3.score(poli_X, y_train_poli)\n",
    "poli_test3 = poli_pipe3.score(poli_X_test, y_test_poli)\n",
    "print(f'LogReg elasticnet, score on training set: {poli_train3}, score on test set: {poli_test3}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:05:59.897934Z",
     "start_time": "2021-03-18T06:05:48.071Z"
    }
   },
   "outputs": [],
   "source": [
    "set(zip(poli_X.columns, lr_net.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:29:54.263465Z",
     "start_time": "2021-03-18T05:26:59.597Z"
    }
   },
   "outputs": [],
   "source": [
    "poli_cvec = pd.DataFrame(cvec.fit_transform(df_poli['text']).todense(), \n",
    "                         columns=cvec.get_feature_names())\n",
    "\n",
    "poli_cvec.sum().sort_values(ascending=False).head(10).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:29:54.263465Z",
     "start_time": "2021-03-18T05:26:59.598Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert training data to dataframe\n",
    "poli_tiff = pd.DataFrame(tvec.fit_transform(df_poli['text']).todense(), \n",
    "                          columns=tvec.get_feature_names())\n",
    "\n",
    "# plot top occuring words\n",
    "poli_tiff.sum().sort_values(ascending=False).head(10).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
